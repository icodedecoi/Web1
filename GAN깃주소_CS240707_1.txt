1)https://github.com/icodedecoi/Web1

2)starGAN
!pip install nnabla-ext-cuda120  
!git clone https://github.com/sony/nnabla-examples.git

!wget -O /content/man.png https://raw.githubusercontent.com/Lilcob/test_colab/main/man.png

%run nnabla-examples/interactive-demos/colab_utils.py
%cd nnabla-examples/image-translation/stargan

!wget https://nnabla.org/pretrained-models/nnabla-examples/GANs/stargan/pretrained_params_on_celebA.h5
!wget https://nnabla.org/pretrained-models/nnabla-examples/GANs/stargan/pretrained_conf_on_celebA.json

def download_and_unzip_dlib_model():
    !wget http://dlib.net/files/mmod_human_face_detector.dat.bz2
    !bzip2 -d mmod_human_face_detector.dat.bz2


def detect_face(image_path):
    image = io.imread(image_path)
    if image.ndim == 2:
        image = color.gray2rgb(image)
    elif image.shape[-1] == 4:
        image = image[..., :3]
    face_detector = dlib.cnn_face_detection_model_v1("mmod_human_face_detector.dat")
    detected_faces = face_detector(cv2.cvtColor(image[..., ::-1].copy(), cv2.COLOR_BGR2GRAY))
    detected_faces = [[d.rect.left(), d.rect.top(), d.rect.right(), d.rect.bottom()] for d in detected_faces]
    assert len(detected_faces) == 1, "Warning: only one face should be contained."
    detected_faces = detected_faces[0]
    return detected_faces, image


def transform(point, center, scale, resolution, invert=False):
    point.append(1)
    h = 200.0 * scale
    t = np.eye(3)
    t[0, 0] = resolution / h
    t[1, 1] = resolution / h
    t[0, 2] = resolution * (-center[0] / h + 0.5)
    t[1, 2] = resolution * (-center[1] / h + 0.5)
    if invert:
        t = np.reshape(np.linalg.inv(np.reshape(t, [1, 3, 3])), [3, 3])
    new_point = np.reshape(np.matmul(
        np.reshape(t, [1, 3, 3]), np.reshape(point, [1, 3, 1])), [3, ])[0:2]
    return new_point.astype(int)


def crop(image, center, scale, resolution=256):
    ul = transform([1, 1], center, scale, resolution, True)
    br = transform([resolution, resolution], center, scale, resolution, True)


    if image.ndim > 2:
        new_dim = np.array([br[1] - ul[1], br[0] - ul[0],
                            image.shape[2]], dtype=np.int32)
        new_img = np.zeros(new_dim, dtype=np.uint8)
    else:
        new_dim = np.array([br[1] - ul[1], br[0] - ul[0]], dtype=np.int)
        new_img = np.zeros(new_dim, dtype=np.uint8)


    ht, wd = image.shape[0], image.shape[1]
    new_x = np.array([max(1, -ul[0] + 1), min(br[0], wd) - ul[0]], dtype=np.int32)
    new_y = np.array([max(1, -ul[1] + 1), min(br[1], ht) - ul[1]], dtype=np.int32)
    old_x = np.array([max(1, ul[0] + 1), min(br[0], wd)], dtype=np.int32)
    old_y = np.array([max(1, ul[1] + 1), min(br[1], ht)], dtype=np.int32)


    new_img[new_y[0] - 1:new_y[1], new_x[0] - 1:new_x[1]] = image[old_y[0] - 1:old_y[1], old_x[0] - 1:old_x[1], :]
    new_img = cv2.resize(new_img, dsize=(int(resolution), int(resolution)),
                         interpolation=cv2.INTER_LINEAR)
    return new_img


def crop_face(detected_faces, image):
    center = [
        detected_faces[2] - (detected_faces[2] - detected_faces[0]) / 2.0,
        detected_faces[3] - (detected_faces[3] - detected_faces[1]) / 2.0
    ]
    scale = (detected_faces[2] - detected_faces[0] + detected_faces[3] - detected_faces[1]) / 195
    cropped_image = crop(image, center, scale, resolution=128)
    return cropped_image


